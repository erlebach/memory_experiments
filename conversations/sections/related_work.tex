\section{Related Work}

\subsection{Memory Models in Cognitive Science}
Howard and Kahana~\cite{howard2002temporal} introduced the Temporal Context Model, which was extended by Polyn et al.~\cite{polyn2009context} into CMR with context reinstatement mechanisms. Gershman et al.~\cite{gershman2017bayesian} developed Bayesian approaches to event segmentation that inform our surprise-based gating.

\subsection{Neural State-Space Models}
Gu et al.~\cite{gu2021s4} introduced Structured State Spaces (S4), while Dao et al.~\cite{dao2023mamba} developed Mamba and Mamba-2 with selective SSM implementations. Sun et al.~\cite{sun2023retnet} proposed Retentive Networks as an alternative to attention mechanisms.


\subsection{Memory-Augmented Neural Networks}
Graves et al.~\cite{graves2016dnc} introduced Differentiable Neural Computers, and Rae et al.~\cite{rae2020compressive} developed Compressive Transformers. Our Titan model builds on surprise-modulated sparse memory approaches.


\subsection{Surprise and Adaptive Gating in Memory}
Gershman~\cite{gershman2019prediction} connected prediction error to memory encoding, while Ritter et al.~\cite{ritter2018meta} explored meta-learning with surprise-based memory. Goyal et al.~\cite{goyal2022retrieval} investigated retrieval-augmented models with adaptive gating.

